{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def dataset_spec(datasetfile,dataset_type,goal_standard,scale = 1,scale_fun=\"mean\",outputdata = True,outfilename='out') \n",
    "##################by RootChen#######################\n",
    "##this function is used for preparation of some open datasets \n",
    "# \n",
    "1、datasetfile (type:string)                                                      #*.txt (supoort for sensorscope and xieye_sysytem dataset) 数据集文件名\n",
    "2、datatype:  (type:string)                                                      #'sensorscope' 、‘xi_eye’                                                 数据集类型\n",
    "##\n",
    "3、goal_standrd: (type:string)                                                 #goal data specification standard 目标标准\n",
    "#3.1  “time series”                                                                #for arima,etc. time serial use\n",
    "#3.2  “llibsvm”                                                                     #standard for libsvm (svm,svdd) +1 1:0.708333 2:1 3:1 4:-0.320755 \n",
    "#3.3  etc\n",
    "##\n",
    "4、scale : (positive integer)                                                    #respample scale.   重采样间隔\n",
    "#4.1   1 (default)                                                                    #means that uses the original dataset. \n",
    "#4.2  n                                                                                #set the scale = n , the dataset after specification will be reduced to nth of the original.\n",
    "##\n",
    "5、scale_fun : (type:string)                                                     #method of scale the dateset               \n",
    "#5.1 mean                                                                            #mean value of  sliding window n 平均数\n",
    "#5.2 median                                                                         #median value of  sliding window n中位数\n",
    "#5.3 other data processing methods\n",
    "##\n",
    "6、outputdata: (type:bool)                                                      # whether output the data to txt\n",
    "#6.1 True (default)\n",
    "#6.2 False\n",
    "##\n",
    "7、outfilename：(type:string)                                                  #output file name if need any file name requirments\n",
    "#out (default)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入库文件\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt #引入绘图库\n",
    "import time\n",
    "import pandas as pd  \n",
    "import datetime\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义函数\n",
    "\n",
    "#本函数用于返回  存储的各数据集用于pandasdataframe 对于的数据属性项\n",
    "def get_pd_attribute(dataset_type):\n",
    "    if dataset_type.strip() ==\"\":\n",
    "        print(\"dataset_type is empty\")\n",
    "    elif dataset_type == \"sensorscope\":\n",
    "        pd_type =  ['ID','Year','Month','Day','Hour','Minute','Second',\\\n",
    "                   'TimeStamp','Sequence Number','Ambient Temperature',\\\n",
    "                    'Surface Temperature','Solar Radiation','Relative Humidity',\\\n",
    "                    'Soil Moisture','Watermark','Rain Meter','Wind Speed',\\\n",
    "                     'Wind Direction']\n",
    "        return pd_type\n",
    "    elif dataset_type == \"xi_eye\":\n",
    "        pd_type =  ['sequence','date','time','am','dest','src','length','groups','type_serial','options',\\\n",
    "                   'thl','etx','origin','originSeqNo','type_x','magic','type','source','sink','source_time',\\\n",
    "                    'sink_time','seqno','period','parent','metric','power','task_time','radio_time','forwarder',\\\n",
    "                    'Humidity',\\\n",
    "                    'Temperature','Photo_active',\\\n",
    "                    'reserved16','reserved32','mark','hopcount','pathlen',\\\n",
    "                     'node_1','node_2','node_3','node_4','node_5','node_6','node_7','node_8','node_9','node_10']\n",
    "        print(len(pd_type))\n",
    "        return pd_type\n",
    "    else:\n",
    "        return \n",
    "#数据流的关闭函数\n",
    "def read_dataset_close(data_object):\n",
    "    data_object.close()     \n",
    "\n",
    "#read_dataset_file文件流方式读取数据集\n",
    "def read_dataset_file(datefile,dataset_type):\n",
    "    if datefile.strip() == '':\n",
    "        print('no filename input')\n",
    "    else:\n",
    "        #打开文件\n",
    "        pd_type = get_pd_attribute(dataset_type)\n",
    "        if pd_type is None:\n",
    "            print('pd_type is null,please write the code in function get_pd_attribute')\n",
    "            return\n",
    "        else:\n",
    "            try:\n",
    "                ###读取txt 文件\n",
    "                data = pd.read_csv(datefile,names = pd_type,sep=' ')\n",
    "                return data\n",
    "            except IOError:\n",
    "                print('文件读取异常！,请输入正确的文件名，或者查看文件目录是否正确')\n",
    "                return\n",
    "#根据数据集的类型提炼整合数据集中有效数据          \n",
    "def data_refine(data,dataset_type,outfile):  #返回子数据集，存储文件到本地文件夹内\n",
    "    if data is None:\n",
    "        print('数据集为空')\n",
    "    else:\n",
    "        ############   sensorscope     ############\n",
    "        if dataset_type =='sensorscope':\n",
    "            print('this is sensorscope')\n",
    "            df = pd.DataFrame({'year':data['Year'],'month':data['Month'],\n",
    "                   'day':data['Day'],'hour':data['Hour'],'minute':data['Minute'],'second':data['Second']})\n",
    "            df = pd.to_datetime(df)\n",
    "            #插入日期数据\n",
    "            data.insert(1,'DateTime',df)\n",
    "            #设置日期列为索引\n",
    "            #data.set_index('DateTime',inplace=True)\n",
    "            \n",
    "            ##***#可修改处，根据获取数据调整，按索引获取。\n",
    "            #subdata = data.get(['DateTime','Ambient Temperature','Surface Temperature','Solar Radiation','Relative Humidity'])\n",
    "            #subdata = data.get(['DateTime','Ambient Temperature','Relative Humidity'])\n",
    "            subdata = data.get(['DateTime','Ambient Temperature'])\n",
    "            subdata.set_index('DateTime',inplace=True)\n",
    "            time = datetime.datetime.now() \n",
    "            time_str = datetime.datetime.strftime(time,'%Y-%m-%d %H:%M:%S')\n",
    "            dirpath = './'+dataset_type+'_'+time_str\n",
    "            if not os.path.exists(dirpath):  #如果不存在该文件夹，则创建\n",
    "                os.mkdir(dirpath)\n",
    "                print(dirpath+'文件夹创建成果')\n",
    "            else:\n",
    "                print('文件存在无需创建')\n",
    "                \n",
    "            path =  dirpath+'/'+outfile\n",
    "            #subdata.to_csv(path,sep=' ',header = False,index=False)    \n",
    "            subdata['Ambient Temperature'].to_csv(path)  \n",
    "            return subdata\n",
    "            #将nan项填充0\n",
    "            \n",
    "        ############   xi_eye     ############\n",
    "        elif dataset_type =='xi_eye':     #使用数据分类后的值\n",
    "            #data['DateTime'] = data['date']+' '+data['time']\n",
    "            #设置日期列为索引\n",
    "            #data.set_index('DateTime',inplace=True)\n",
    "            ###可修改处，根据获取数据调整，按索引获取。\n",
    "            subdata = data.get(['date','time','origin','Temperature','Humidity','Photo_active'])\n",
    "            #dataframe按照ID数据重新排序\n",
    "            subdata=subdata.sort_values(by=\"origin\")\n",
    "            subdata.drop_duplicates(subset=['date','time','origin'],keep='first',inplace=True)  #inplace = True 表示删除样本，false 表示将重复的部分另存一下副本\n",
    "            #按照ID输出到txt文件中  \n",
    "            #获取当前系统时间，以时间作名字，创建文件夹\n",
    "            time = datetime.datetime.now() \n",
    "            time_str = datetime.datetime.strftime(time,'%Y-%m-%d %H:%M:%S')\n",
    "            print(time_str)\n",
    "            dirpath = './'+dataset_type+'_'+time_str   #文件夹名字 时间+数据集类型\n",
    "            if not os.path.exists(dirpath):  #如果不存在该文件夹，则创建\n",
    "                os.mkdir(dirpath)\n",
    "                print(dirpath+'文件夹创建成果')\n",
    "            else:\n",
    "                print('文件存在无需创建')\n",
    "    \n",
    "            for i in range(100,131):\n",
    "                #print(data_object[data_object['origin']==i])\n",
    "                if not subdata[data_object['origin']==i].empty :\n",
    "                    \n",
    "                    df = subdata[data_object['origin']==i]\n",
    "                    #print(df)\n",
    "                    #time = datetime.datetime.now() \n",
    "                    #time_str = datetime.datetime.strftime(time,'%Y-%m-%d %H:%M:%S')\n",
    "                    path = dirpath+'/'+outfile+str(i)\n",
    "                    #outfilename = 'out'+str(i)+' '+time_str+'.txt'\n",
    "                    df.to_csv(path,sep=' ',header = True,index=False)\n",
    "                    \n",
    "            #print(subdata)\n",
    "            return subdata\n",
    "        else:\n",
    "            print('请在get_pd_attribute、data_refine函数中定义新的数据集 **%s **的数据属性和数据提炼方法',dataset_type)\n",
    "            return \n",
    "        \n",
    "        \n",
    "#data resample  #参数dataframe  scale 比例 scalefun 算法函数 返回dataframe\n",
    "#dataframe设计到时间的项，处理事将时间项和其他变量分开处理，时间项按比例的最后时间为准，其他项则进行处理。\n",
    "def dataresample(data,scale,scalefun='interval'):  # 1、interval sample  2、mean resample   3、median resample  4、protoco\n",
    "    #print('data的index',data.shape)\n",
    "    #print('data的column',data.columns)\n",
    "    #判断data是否为空\n",
    "    if not data.empty:\n",
    "        if scale>=1:  #判断数据重采样比例是否正常>=1\n",
    "            if scalefun=='interval':\n",
    "                rows = data.shape[0]\n",
    "                index = np.arange(0,rows,1)\n",
    "                #select_index = index[index%scale==0]\n",
    "                select_index=index[index%scale==scale-1]   #取间隔最后一个值作为时间索引\n",
    "                subdata = data.loc[select_index]\n",
    "                #print(subdata)\n",
    "                return subdata\n",
    "            elif scalefun=='mean':\n",
    "                #新建dataframe对象，每十个数据行求平均，加入到dataframe中\n",
    "                rows = data.shape[0]\n",
    "                #index = np.arange(0,rows,1)\n",
    "                internal = scale\n",
    "                #temp = scale-1\n",
    "                 #subdata=data_object.loc[select_index]\n",
    "                #subdata\n",
    "                #由于求平均操作时间值不可以计算，所以提取数据中的时间列 和数据列。\n",
    "                timedf = data[['DateTime']]\n",
    "                #print(timedf)\n",
    "                timedf = dataresample(timedf,internal,scalefun='interval')\n",
    "                timedf = timedf.reset_index(drop=True)\n",
    "                #print(timedf)\n",
    "                #datadf = data[['Ambient Temperature','Surface Temperature','Solar Radiation','Relative Humidity']]\n",
    "                #####可修改处\n",
    "                #datadf = data[['Ambient Temperature','Relative Humidity']]\n",
    "                datadf = data[['Ambient Temperature']]\n",
    "               \n",
    "                newdataframe = pd.DataFrame(columns=datadf.columns)\n",
    "                #按照间隔求数值部分平均值\n",
    "                for i  in range(rows//internal+1):\n",
    "                    begin = i*internal\n",
    "                    end = begin+internal\n",
    "                    if end >rows:\n",
    "                        end = rows\n",
    "                    newdataframe.loc[i] = datadf[begin:end].apply(lambda x: x.mean())   #求区间的平均值\n",
    "                #print(newdataframe)\n",
    "                #result = pd.merge(timedf,newdataframe,left_index=True,right_index=True)\n",
    "                result = timedf.join(newdataframe)\n",
    "                return result\n",
    "                    \n",
    "            elif scalefun=='median':\n",
    "                pass\n",
    "            else:\n",
    "                print('请在dataresample(data,scale,scalefun=interval)函数中添加相应重采样代码')\n",
    "                pass\n",
    "                \n",
    "        else:      #缩减返回值<1.显示异常\n",
    "            print('dataresample(data,scale,scalefun=interval).  scale 值为空')\n",
    "            return \n",
    "    else:# 文件打开失败\n",
    "        print('dataresample(data,scale,scalefun=interval).  data 值为空')\n",
    "        return\n",
    "\n",
    "##转化格式 libsvm\n",
    "def format_data_forlibsvm(data,labels,outfile):  #输入dataframe变量、标签变量(训练集、测试集预先设定)。输出data数据至文本\n",
    "    #待完成\n",
    "    #1、插入异常值 label = -1  short+10  noise 随机噪声。\n",
    "    \n",
    "    \n",
    "    #规约数据集至[-1,1]或者[0,1], 返回每列的平均。\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reSample(df,datatype,interval):  #df包含时间、数值。 interval 代表间隔周期\n",
    "    #data_refine函数中已经处理过时间数据\n",
    "    #sub = df[['DateTime',datatype]]\n",
    "    #sub['Date'].astype('datetime64')\n",
    "    #sub['DateTime'] = pd.to_datetime(sub['DateTime'])\n",
    "    #sub.set_index('DateTime',inplace=True)\n",
    "    resampe_sub = df.resample(interval).mean()\n",
    "    return resampe_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data_object.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test1 read dataset\n",
    "#data_object=read_dataset_file('data_c1.txt','xi_eye')  #xi_eye\n",
    "datafilename = 'sensorscope-meteo-3.txt'\n",
    "data_object=read_dataset_file(datafilename,'sensorscope')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is sensorscope\n",
      "./sensorscope_2019-01-10 10:54:56文件夹创建成果\n"
     ]
    }
   ],
   "source": [
    "##2数据提炼\n",
    "#data_object=data_refine(data_object,'xi_eye','testtest')   #xi_eye\n",
    "outputfile = datafilename+ '.csv'\n",
    "data_object=data_refine(data_object,'sensorscope',outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取子集\n",
    "\n",
    "subtype1 = '10min'\n",
    "subtype2 = '30min'\n",
    "subtype3 = '1h'\n",
    "subdata1 = reSample(data_object,'Ambient Temperature',subtype1)\n",
    "subdata2 = reSample(data_object,'Ambient Temperature',subtype2)\n",
    "subdata3 = reSample(data_object,'Ambient Temperature',subtype3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subdata.head()\n",
    "outfilename1 = datafilename +'_'+subtype1+ '.csv'\n",
    "outfilename2 = datafilename +'_'+subtype2+ '.csv'\n",
    "outfilename3 = datafilename +'_'+subtype3+ '.csv'\n",
    "subdata1['Ambient Temperature'].to_csv(outfilename1)\n",
    "subdata2['Ambient Temperature'].to_csv(outfilename2)\n",
    "subdata3['Ambient Temperature'].to_csv(outfilename3)\n",
    "#data_object.drop_duplicates(subset=['DateTime','origin'],keep='first',inplace=True)  #inplace = True 表示删除样本，false 表示将重复的部分另存一下副本\n",
    "#data_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(100,131):\n",
    "    #print(data_object[data_object['origin']==i])\n",
    "    if not data_object[data_object['origin']==i].empty :\n",
    "        df = data_object[data_object['origin']==i]\n",
    "        print(df)\n",
    "        outfilename = 'out'+str(i)+'.txt'\n",
    "        df.to_csv(outfilename,sep=' ',header = False,index=False)\n",
    "        #print(data_object[data_object['origin']==i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test3 创建文件夹\n",
    "'''\n",
    "time1 = datetime.datetime.now() \n",
    "time1_str = datetime.datetime.strftime(time1,'%Y-%m-%d %H:%M:%S')\n",
    "time1_str\n",
    "os.mkdir(time1_str)\n",
    "#path = os.path.realpath(__file__)\n",
    "outfilename = 'out'\n",
    "path = time1_str+'/'+outfilename\n",
    "data_object.to_csv(path,sep=' ',header = False,index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##test 4 resample\n",
    "# 重采样\n",
    "''' interval\n",
    "dataresample(data_object,10)\n",
    "\n",
    "rows = data_object.shape[0]\n",
    "index = np.arange(0,rows,1)\n",
    "select_index=index[index%10==0]\n",
    "subdata=data_object.loc[select_index]\n",
    "subdata\n",
    "'''\n",
    "#mean\n",
    "'''\n",
    "rows = data_object.shape[0]\n",
    "index = np.arange(0,rows,1)\n",
    "internal = 4\n",
    "select_index=index[index%internal==0]\n",
    "#subdata=data_object.loc[select_index]\n",
    "#subdata\n",
    "\n",
    "timedf = data_object[['DateTime']]\n",
    "print(timedf)\n",
    "timedf = dataresample(timedf,internal,scalefun='interval')\n",
    "print(timedf)\n",
    "datadf = data_object[['Ambient Temperature','Surface Temperature','Solar Radiation','Relative Humidity']]\n",
    "newdataframe = pd.DataFrame(columns=datadf.columns)\n",
    "index==0\n",
    "for i  in range(datadf.shape[0]//internal+1):\n",
    "    begin = i*internal\n",
    "    end = begin+internal\n",
    "    if end >datadf.shape[0]:\n",
    "        end = datadf.shape[0]\n",
    "    #subdata = data_object[begin:end].mean()\n",
    "    #print(subdata)\n",
    "    #print(subdata.shape)\n",
    "    #newdataframe.append(subdata,ignore_index=True)\n",
    "    newdataframe.loc[i] = datadf[begin:end].apply(lambda x: x.mean())\n",
    "'''\n",
    "#整合两个dataframe\n",
    "#newdataframe\n",
    "#timedf.merge(newdataframe, left_on='DateTime', right_on='Ambient Temperature', how='outer')\n",
    "#newdataframe.reset_index(drop=True)\n",
    "'''\n",
    "print(newdataframe)\n",
    "timedf=timedf.reset_index(drop=True)\n",
    "print(timedf)\n",
    "data_object=timedf.join(newdataframe)\n",
    "#newdataframe['index'] = newdataframe.index.apply(lambda x: x)\n",
    "''''''\n",
    "l1 = range(newdataframe.shape[0])\n",
    "print(l1)\n",
    "index1 = pd.Series(l1)\n",
    "#index1 = index1.astype('float64')\n",
    "print(index1)\n",
    "newdataframe['join']=index1\n",
    "#newdataframe.insert(1,'join',index1)\n",
    "l2 = range(timedf.shape[0])\n",
    "index2 = pd.Series(l2)\n",
    "timedf['join']=index2\n",
    "\n",
    "print(newdataframe)\n",
    "print(timedf)\n",
    "'''\n",
    "'''\n",
    "#result=pd.merge(timedf,newdataframe)\n",
    "'''\n",
    "#result = pd.merge(timedf,newdataframe,left_index=True,right_index=True)\n",
    "#result\n",
    "data_object = dataresample(data_object,4,scalefun='mean')\n",
    "data_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for row in range(0,rows = data_object.shape[0]):\n",
    " #   print(data_object.iloc[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test 5  格式转化输出 t x t  dataframe\n",
    "columns = data_object.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
